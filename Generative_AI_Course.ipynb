{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kgatarski/openaiApi_training/blob/main/Generative_AI_Course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LuSRu90vhG9U"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "key=userdata.get('openai_key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzCv4iZzXrAe",
        "outputId": "e5ba149a-c700-467a-d876-2010279d0692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28.1) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28.1) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28.1) (3.12.14)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.1) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.1) (2025.7.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.1) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->openai==0.28.1) (4.14.1)\n",
            "Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.97.1\n",
            "    Uninstalling openai-1.97.1:\n",
            "      Successfully uninstalled openai-1.97.1\n",
            "Successfully installed openai-0.28.1\n"
          ]
        }
      ],
      "source": [
        "#!pip install openai\n",
        "!pip install openai==0.28.1\n",
        "import openai\n",
        "openai.api_key = key\n",
        "\n",
        "def Generate_Content(question, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": question}]\n",
        "    openai_response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages\n",
        "    )\n",
        "    return openai_response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q127Y4DmJn_g",
        "outputId": "a42815ad-289f-492f-ab98-6f31e3ffeb7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a Python program that checks if a number is prime or not:\n",
            "\n",
            "```python\n",
            "def is_prime(num):\n",
            "    if num <= 1:\n",
            "        return False\n",
            "    if num <= 3:\n",
            "        return True\n",
            "    if num % 2 == 0 or num % 3 == 0:\n",
            "        return False\n",
            "    i = 5\n",
            "    while i * i <= num:\n",
            "        if num % i == 0 or num % (i + 2) == 0:\n",
            "            return False\n",
            "        i += 6\n",
            "    return True\n",
            "\n",
            "num = int(input(\"Enter a number: \"))\n",
            "if is_prime(num):\n",
            "    print(f\"{num} is a prime number\")\n",
            "else:\n",
            "    print(f\"{num} is not a prime number\")\n",
            "```\n",
            "\n",
            "This program defines a function `is_prime` that checks if a given number is prime or not using the optimized primality test algorithm. The user is prompted to enter a number, and the program then prints whether the number is prime or not.\n",
            "total 20\n",
            "drwxr-xr-x 1 root root 4096 Aug  6 11:03 .\n",
            "drwxr-xr-x 1 root root 4096 Aug  6 11:02 ..\n",
            "drwxr-xr-x 4 root root 4096 Jul 29 13:36 .config\n",
            "-rw-r--r-- 1 root root  751 Aug  6 11:11 response.txt\n",
            "drwxr-xr-x 1 root root 4096 Jul 29 13:36 sample_data\n",
            "\n",
            "overlay on / type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay2/l/6YKRMOTYMCGU4IUJLTNFCIO35U:/var/lib/docker/overlay2/l/UPMS5B53UZEP5XIR66AAJJ6KPL:/var/lib/docker/overlay2/l/TDA3RER3Y3QHUP6EHPDHT54X6B:/var/lib/docker/overlay2/l/CFV3UVBVCLSLZW63RL4WGIODAW:/var/lib/docker/overlay2/l/JWVK5LLEXMDSI44B3S3UOYAVNK:/var/lib/docker/overlay2/l/V6O742ZSNEDGQUVALTJJCXLSB2:/var/lib/docker/overlay2/l/YDZEHUG3QTY3OP7OA3UKWNPW2O:/var/lib/docker/overlay2/l/MEBMR6HLHH3G7ZJPNXZOBW4RSA:/var/lib/docker/overlay2/l/MJMZHW4MUFKZQXXES3W3X3L65K:/var/lib/docker/overlay2/l/LBUWKU6S2TJMLKA7K5UJQRGMS6:/var/lib/docker/overlay2/l/MR6GYIFS22CXC7FHB2M2TO2OGK:/var/lib/docker/overlay2/l/QZVZ6QQMJL2W5JWQDRBDRUZXXG:/var/lib/docker/overlay2/l/HRNQOHPQ2V3UYBCA6UTFOBNI5R:/var/lib/docker/overlay2/l/7SITPE5RY2BUVSAGY3SUYRYGV7:/var/lib/docker/overlay2/l/RGZQWH4GHH3ORCGKPKJSYACDZD:/var/lib/docker/overlay2/l/RIFWBMTU6T76ZG3X6HA4E2FZUA:/var/lib/docker/overlay2/l/UZZN3VCT2RHFDEY4X5RETEOZRZ:/var/lib/docker/overlay2/l/KZSSMDDLRFWBGOYKOCSBN7HTSH:/var/lib/docker/overlay2/l/W6ZFCEBYJ3FGQ6YBIUDJ2NGMGZ:/var/lib/docker/overlay2/l/MSNZA3MXPUNDT32NK7FROX5J7N:/var/lib/docker/overlay2/l/PDU2MVUVFZEYVIHKRRJL4YQ66C:/var/lib/docker/overlay2/l/FEDQKSP6A624FDPHQC3PWCR7UZ:/var/lib/docker/overlay2/l/HNO3JDCCE5675HCUGIBGUME74Q:/var/lib/docker/overlay2/l/6DQA4NNHCX4WPUO6OPSLCS4O5J:/var/lib/docker/overlay2/l/DDYQNJCFBEVN776VUTKVYO5ESO:/var/lib/docker/overlay2/l/F2OCAVAK4ZFDKMIOOLAREZ5JBF:/var/lib/docker/overlay2/l/3MVHGL2GASZQGEM5XLINHVV7MD:/var/lib/docker/overlay2/l/UWXDQ5NDNAVBT3D2K6NHBCDLWY:/var/lib/docker/overlay2/l/VXHAQRPRHTEZAPMBFOWJOXYU7G:/var/lib/docker/overlay2/l/3H6UTHINIWIV7PJ7UOPVQ2H652:/var/lib/docker/overlay2/l/PFBQMMK73BSV3RNHIKSBP2MCVI:/var/lib/docker/overlay2/l/3FA5CZ4NI3HN5BFDRBRUDDJF76:/var/lib/docker/overlay2/l/R34TO2HNBKCMBMGFR5X2E3OXLZ:/var/lib/docker/overlay2/l/Z5VQOXMYPL3PORZGVQ5A2VZ7X2:/var/lib/docker/overlay2/l/O5CRI52MJWT4GQZGPXX5YUZ7IQ:/var/lib/docker/overlay2/l/QRFS2XFZRDONIEYN7HC5Q6T2I3:/var/lib/docker/overlay2/l/5EIPSZZMEWAA4O7HFEDPLKDYK5:/var/lib/docker/overlay2/l/QB5C3TRQ622IRUA5OCYLOL4HCA:/var/lib/docker/overlay2/l/ZHW3C5IJNAKHJ4RZFNGF7W3UEQ:/var/lib/docker/overlay2/l/VYMTMT77TWHC54RKLI3NAOUFLI:/var/lib/docker/overlay2/l/WFSW3WRFO2YVA2LU6RQBTJJ7BO:/var/lib/docker/overlay2/l/DJSNYIYRLH7K57EY7UEURODZBU:/var/lib/docker/overlay2/l/7VGMASE37VBWMPWBC6YMOJNJGO:/var/lib/docker/overlay2/l/KLIM2NEHJVWOIS77FT2EHN7I3J:/var/lib/docker/overlay2/l/5HSVIZYX5Z5I6H3SZQNTNRUDZY:/var/lib/docker/overlay2/l/7U4VAQPGQY2RRUMLWBM4LCI7I3:/var/lib/docker/overlay2/l/RZJJ57E7COSIXEOHLXKDI36XKR:/var/lib/docker/overlay2/l/FKMZBLPWGNGQT2X2NI6UM7SL4Y:/var/lib/docker/overlay2/l/QNF6FYUSVU4H2JAHRPEX6Y2U5R:/var/lib/docker/overlay2/l/S3UJDZJHPQCQNACV2BBXOSSYMK:/var/lib/docker/overlay2/l/BUTGFBPCXT3ERQXY5UXJ5OA4RM:/var/lib/docker/overlay2/l/BV45E2APU3DTBNADFVO3WHAKW6:/var/lib/docker/overlay2/l/RKF7IFFIWK3TXJYSNZ7FN26XGX:/var/lib/docker/overlay2/l/E6PW4JM6Z3SRIYG2SSIIN7L4OM:/var/lib/docker/overlay2/l/OIDTM4SKIX67I5M7RFMHUW2KPP:/var/lib/docker/overlay2/l/4EXGYDRW5LA77CLQ626ZAP334G:/var/lib/docker/overlay2/l/5LNO6WUVAKQ3V46SQEBFUKACGG:/var/lib/docker/overlay2/l/3IV6IJU4KTN4SMOWPRYKYARA3W:/var/lib/docker/overlay2/l/NLB6DQSIH3A7XZMYNAR3T43PPT:/var/lib/docker/overlay2/l/WQNYUBA5JCEKRLU57JJJDDPIVF:/var/lib/docker/overlay2/l/C65YVXMCYHNEPDEXSRZIMMYRVZ:/var/lib/docker/overlay2/l/SFJJ657DWNKGZBH2NZP2IIPLYQ:/var/lib/docker/overlay2/l/P774XVZHTGXYOHNRT75YS3LQLQ,upperdir=/var/lib/docker/overlay2/98b3d5b16174bba86d1b9d506ec06c6c6d97ba636edab165e632269ae90165ae/diff,workdir=/var/lib/docker/overlay2/98b3d5b16174bba86d1b9d506ec06c6c6d97ba636edab165e632269ae90165ae/work)\n",
            "proc on /proc type proc (rw,nosuid,nodev,noexec,relatime)\n",
            "tmpfs on /dev type tmpfs (rw,nosuid,size=65536k,mode=755)\n",
            "devpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=666)\n",
            "sysfs on /sys type sysfs (ro,nosuid,nodev,noexec,relatime)\n",
            "cgroup on /sys/fs/cgroup type cgroup2 (ro,nosuid,nodev,noexec,relatime,nsdelegate)\n",
            "mqueue on /dev/mqueue type mqueue (rw,nosuid,nodev,noexec,relatime)\n",
            "shm on /dev/shm type tmpfs (rw,nosuid,nodev,noexec,relatime,size=5989376k)\n",
            "/dev/dm-0 on /usr/sbin/docker-init type ext2 (ro,relatime)\n",
            "tmpfs on /tmp/colab_runtime.sock type tmpfs (rw,nosuid,nodev,noexec)\n",
            "/dev/sda1 on /kaggle/input type ext4 (ro,relatime,commit=30)\n",
            "tmpfs on /var/colab type tmpfs (rw,nosuid,nodev,noexec)\n",
            "/dev/sda1 on /etc/resolv.conf type ext4 (rw,nosuid,nodev,relatime,commit=30)\n",
            "/dev/sda1 on /etc/hostname type ext4 (rw,nosuid,nodev,relatime,commit=30)\n",
            "/dev/sda1 on /etc/hosts type ext4 (rw,nosuid,nodev,relatime,commit=30)\n",
            "cgroup2 on /var/colab/cgroup/jupyter-children type cgroup2 (ro,relatime,nsdelegate)\n",
            "proc on /proc/bus type proc (ro,nosuid,nodev,noexec,relatime)\n",
            "proc on /proc/fs type proc (ro,nosuid,nodev,noexec,relatime)\n",
            "proc on /proc/irq type proc (ro,nosuid,nodev,noexec,relatime)\n",
            "proc on /proc/sys type proc (ro,nosuid,nodev,noexec,relatime)\n",
            "proc on /proc/sysrq-trigger type proc (ro,nosuid,nodev,noexec,relatime)\n",
            "tmpfs on /proc/acpi type tmpfs (ro,relatime)\n",
            "tmpfs on /proc/kcore type tmpfs (rw,nosuid,size=65536k,mode=755)\n",
            "tmpfs on /proc/keys type tmpfs (rw,nosuid,size=65536k,mode=755)\n",
            "tmpfs on /proc/timer_list type tmpfs (rw,nosuid,size=65536k,mode=755)\n",
            "tmpfs on /proc/scsi type tmpfs (ro,relatime)\n",
            "tmpfs on /sys/firmware type tmpfs (ro,relatime)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Summarize Alice in the wonderland in 3 sentences\n",
        "\"\"\"\n",
        "\n",
        "prompt1 = f\"\"\"\n",
        "Write a program to check if a number is prime or not\n",
        "\"\"\"\n",
        "\n",
        "response = Generate_Content(prompt1)\n",
        "print(response)\n",
        "\n",
        "f=open('response.txt','w')\n",
        "f.write(response)\n",
        "f.close()\n",
        "\n",
        "import subprocess\n",
        "\n",
        "# Wywołanie polecenia 'ls -la'\n",
        "result = subprocess.run(['ls', '-la'], capture_output=True, text=True)\n",
        "pwdRresult = subprocess.run(['mount'], capture_output=True, text=True)\n",
        "\n",
        "# Wyświetlenie wyniku\n",
        "print(result.stdout)\n",
        "print(pwdRresult.stdout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LZR11TLLdzO"
      },
      "source": [
        "### Prompt engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sxx_slyQG3s"
      },
      "source": [
        "**Deriving Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pNE9sHzcQVtu"
      },
      "outputs": [],
      "source": [
        "review = \"\"\"\n",
        "The cashier wasn't responding to me though i tried to contact\n",
        "him repeatedly. Also the product is overpriced. At the end I am happy with new bike.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64ljpvCSRRKb",
        "outputId": "cad770b7-9c1a-4d5b-fbaf-f79d6eec871b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment in the product review is negative. The customer is expressing dissatisfaction with the service received from the cashier and feels that the product they purchased is overpriced. Overall, they are unhappy with their new bike.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment in the product review,\n",
        "which is delimited with triple backticks?\n",
        "'''{review}'''\n",
        "\"\"\"\n",
        "response = Generate_Content(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LzFqeBORZDF",
        "outputId": "65d5a5b4-834f-4803-aae4-7921611551ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Frustration\n",
            "2. Disappointment\n",
            "3. Anger\n",
            "4. Satisfaction\n",
            "5. Contentment\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the top five emotions conveyed in the product review,\n",
        "which is delimited with triple backticks?\n",
        "'''{review}'''\n",
        "\"\"\"\n",
        "response = Generate_Content(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm9Rh7B7RdBT",
        "outputId": "88c47f48-9a6b-456a-c30c-6757c23eee4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes, frustration is present in the product review.\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Is frustration present in the product review,\n",
        "which is delimited with triple backticks?\n",
        "'''{review}'''\n",
        "\"\"\"\n",
        "response = Generate_Content(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ndzo9xSgH_"
      },
      "source": [
        "**Expanding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqxNkattS2OR",
        "outputId": "d674c36f-d6b6-441c-e9ae-957dd2e2d4eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear valued customer,\n",
            "\n",
            "Thank you for taking the time to provide us with your feedback. We always appreciate hearing from our customers, whether the review is positive or negative.\n",
            "\n",
            "We are truly sorry to hear about the experience you had with our cashier. We strive to provide excellent customer service, and it is disappointing to hear that this was not the case for you. We will definitely address this issue with our team to ensure that it does not happen again in the future.\n",
            "\n",
            "Additionally, we apologize if you found our product to be overpriced. We always aim to offer fair and competitive prices to our customers. \n",
            "\n",
            "In light of your feedback, we would like to offer you a small discount of 15% for your next purchase with us. We hope that this gesture can help make up for any inconvenience you experienced.\n",
            "\n",
            "We are glad to hear that you are happy with your new bike, and we hope that you continue to enjoy it for a long time to come.\n",
            "\n",
            "Thank you once again for your feedback and for being a valued customer. We look forward to serving you again soon.\n",
            "\n",
            "Best regards,\n",
            "[Your Name]\n",
            "Customer Service Team\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Behave like a customer service agent.\n",
        "Generate a email to reply to the customer\n",
        "who provide the review , which is delimited\n",
        "with backslashes.\n",
        "Thanks the customer first.  Apologize if the review is negative and propose a small discount [10-15%] for next shops.\n",
        "Use details from the review and compose a response in a professional tone.\n",
        "\\\\{review}\\\\\n",
        "\"\"\"\n",
        "response = Generate_Content(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcARGNEUcACQ"
      },
      "source": [
        "**Moderation API**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-iGX5PDa0mc",
        "outputId": "38195b73-fa3b-4aa0-9827-d36d42df5165"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categories: {\n",
            "  \"sexual\": false,\n",
            "  \"hate\": true,\n",
            "  \"harassment\": true,\n",
            "  \"self-harm\": false,\n",
            "  \"sexual/minors\": false,\n",
            "  \"hate/threatening\": false,\n",
            "  \"violence/graphic\": false,\n",
            "  \"self-harm/intent\": false,\n",
            "  \"self-harm/instructions\": false,\n",
            "  \"harassment/threatening\": false,\n",
            "  \"violence\": false\n",
            "}\n",
            "Category Scores: {\n",
            "  \"sexual\": 3.3189680834766477e-06,\n",
            "  \"hate\": 0.997710108757019,\n",
            "  \"harassment\": 0.9997679591178894,\n",
            "  \"self-harm\": 6.255296739254845e-06,\n",
            "  \"sexual/minors\": 2.794616023038543e-07,\n",
            "  \"hate/threatening\": 8.723377504793461e-07,\n",
            "  \"violence/graphic\": 1.3127240094945591e-07,\n",
            "  \"self-harm/intent\": 3.505364247757825e-06,\n",
            "  \"self-harm/instructions\": 7.004760391282616e-06,\n",
            "  \"harassment/threatening\": 2.0479542399698403e-06,\n",
            "  \"violence\": 0.0003027828352060169\n",
            "}\n",
            "{\n",
            "  \"id\": \"modr-C1Wu6ZH1Iz4HDoOzosk3rEgHKw6OE\",\n",
            "  \"model\": \"text-moderation-007\",\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"flagged\": true,\n",
            "      \"categories\": {\n",
            "        \"sexual\": false,\n",
            "        \"hate\": true,\n",
            "        \"harassment\": true,\n",
            "        \"self-harm\": false,\n",
            "        \"sexual/minors\": false,\n",
            "        \"hate/threatening\": false,\n",
            "        \"violence/graphic\": false,\n",
            "        \"self-harm/intent\": false,\n",
            "        \"self-harm/instructions\": false,\n",
            "        \"harassment/threatening\": false,\n",
            "        \"violence\": false\n",
            "      },\n",
            "      \"category_scores\": {\n",
            "        \"sexual\": 3.3189680834766477e-06,\n",
            "        \"hate\": 0.997710108757019,\n",
            "        \"harassment\": 0.9997679591178894,\n",
            "        \"self-harm\": 6.255296739254845e-06,\n",
            "        \"sexual/minors\": 2.794616023038543e-07,\n",
            "        \"hate/threatening\": 8.723377504793461e-07,\n",
            "        \"violence/graphic\": 1.3127240094945591e-07,\n",
            "        \"self-harm/intent\": 3.505364247757825e-06,\n",
            "        \"self-harm/instructions\": 7.004760391282616e-06,\n",
            "        \"harassment/threatening\": 2.0479542399698403e-06,\n",
            "        \"violence\": 0.0003027828352060169\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "response = openai.Moderation.create(\n",
        "  input=\"you ugly gay.\"\n",
        ")\n",
        "input2=\"while at war with intense gunfire ripping human limbs.\"\n",
        "categories = response['results'][0]['categories']\n",
        "category_scores = response['results'][0]['category_scores']\n",
        "\n",
        "print(\"Categories:\", categories)\n",
        "print(\"Category Scores:\", category_scores)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NJDeJLIMV6e"
      },
      "source": [
        "**Different Roles**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "eV4HGY1EMYzp"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are an astronomy expert.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is the 5th planet in solar system?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"It is Jupiter\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is the next planet?\"}\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBT7DE5FPKf2",
        "outputId": "0b48fe80-c764-4ff2-9b9b-0aace3ca2caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-C1WzyKVfqjAjlj6qihbfAExJgh4oL\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1754481210,\n",
            "  \"model\": \"gpt-3.5-turbo-0125\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"After Jupiter, the next planet in the solar system is Saturn.\",\n",
            "        \"refusal\": null,\n",
            "        \"annotations\": []\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\"\n",
            "    }\n",
            "  ],\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 45,\n",
            "    \"completion_tokens\": 13,\n",
            "    \"total_tokens\": 58,\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"cached_tokens\": 0,\n",
            "      \"audio_tokens\": 0\n",
            "    },\n",
            "    \"completion_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    }\n",
            "  },\n",
            "  \"service_tier\": \"default\",\n",
            "  \"system_fingerprint\": null\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "res=response['choices'][0]['message']['content']\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYATZN1VXgdf"
      },
      "source": [
        "**Chaining Prompts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_rJMhHX5oM2",
        "outputId": "02426c06-e7fd-41ab-d27d-1898c92f50d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: The user is asking about the Apple iPhone product which is listed for $200. \n",
            "Step 2: I'm sorry, but the Apple iPhone is available for $200 and not $150 as mentioned in your question. \n",
            "Step 3: The Apple iPhone will be shipped 3 days after the order is placed. Thank you for your inquiry.\n"
          ]
        }
      ],
      "source": [
        "question=\"\"\"Is Apple iphone available for $150?\"\"\"\n",
        "prompt = f\"\"\" Follow the below three steps to respond to question from customer\n",
        "which is delimited with triple backticks?'''{question}'''\n",
        "Use the following 3 steps and compose a concise answer:\n",
        "\n",
        "Step 1: If the user is asking about any of the products below move ahead.\n",
        "Otherwise proceed to step 3.\n",
        "1. Product: Apple iphone;   Price: $ 200\n",
        "2. Product: Samsung TV;   Price: $ 100\n",
        "3. Product: Sony Hometheater;   Price: $ 150\n",
        "Step 2: If the message contains products\n",
        "listed above, validate the assumption of user and inform if it is wrong\n",
        "Step 3: If the message contains products listed above, tell the user that\n",
        "product will be shipped 3 days after order.Otherwise mention that product\n",
        "doesn't exist currently.\"\"\"\n",
        "response = Generate_Content(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kqVsaV6KI3M"
      },
      "source": [
        "### Using LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsn6hJCcSz7K"
      },
      "source": [
        "**Using LangChain**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYdTeVYcRtyK",
        "outputId": "1b756dfd-dad2-4819-98bf-a924d7280d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core\n",
            "  Downloading langchain_core-0.2.1-py3-none-any.whl (308 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.5/308.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.0 (from langchain-community)\n",
            "  Downloading langchain-0.2.0-py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain-community)\n",
            "  Downloading langsmith-0.1.62-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.3/122.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.3.0)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.7.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-community)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.6 jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.0 langchain-community-0.2.0 langchain-core-0.2.1 langchain-text-splitters-0.2.0 langsmith-0.1.62 marshmallow-3.21.2 mypy-extensions-1.0.0 orjson-3.10.3 packaging-23.2 typing-inspect-0.9.0\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.6)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.62)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-community langchain-core\n",
        "!pip install --upgrade langchain\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "chat = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\", openai_api_key=key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7Nv7BFGS4MG",
        "outputId": "f8735a48-2367-4fd4-bec8-70363dd0a74a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "template_string = \"\"\"Translate the text \\\n",
        "that is delimited by triple backticks \\\n",
        "into a style that is {style}. \\\n",
        "text: ```{text}```\n",
        "\"\"\"\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
        "\n",
        "prompt_template.messages[0].prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z3vWU5YuZwE"
      },
      "outputs": [],
      "source": [
        "customer_style = \"\"\"American English \\\n",
        "in a calm and respectful tone\n",
        "\"\"\"\n",
        "customer_email = \"\"\"\n",
        "Let's have a barbecue. G'day mate! Hey friend! Do you wanna\n",
        "hang out this arvo?\n",
        "\"\"\"\n",
        "customer_messages = prompt_template.format_messages(\n",
        "                    style=customer_style,\n",
        "                    text=customer_email)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5RxCNONTSXM",
        "outputId": "728dde96-1f5e-46a1-8349-5331052d61c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's have a barbecue. Hello friend! Hey buddy! Do you want to hang out this afternoon?\n"
          ]
        }
      ],
      "source": [
        "customer_response = chat(customer_messages)\n",
        "print(customer_response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faIG-7zVsksk"
      },
      "source": [
        "**Managing Memory**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Without using memmory\n",
        "print(Generate_Content(\"My name is Alex\"))\n",
        "print(Generate_Content(\"How much is 1 kilogram?\"))\n",
        "print(Generate_Content(\"What is my name?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf_mCIpnIQqB",
        "outputId": "3a740325-0ebc-449c-e0e4-be495cc59fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Alex! How can I assist you today?\n",
            "1 kilogram is equal to approximately 2.20462 pounds.\n",
            "I'm sorry, I cannot determine your name as I am an AI Assistant and do not have access to personal information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OG0QhKqVso9G"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "llm = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\", openai_api_key=key)\n",
        "memory = ConversationBufferMemory()\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory = memory,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQitP8JtvWai",
        "outputId": "3bf5f14e-c855-469b-ad2a-26e7e4429028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: My name is Alex\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: My name is Alex\n",
            "AI: Hello Alex! It's nice to meet you. How can I assist you today?\n",
            "Human: How much is 1 kilogram?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: My name is Alex\n",
            "AI: Hello Alex! It's nice to meet you. How can I assist you today?\n",
            "Human: How much is 1 kilogram?\n",
            "AI: 1 kilogram is equal to 1000 grams. It is a unit of mass in the metric system. Is there anything else you would like to know?\n",
            "Human: What is my name?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Human: My name is Alex\n",
            "AI: Hello Alex! It's nice to meet you. How can I assist you today?\n",
            "Human: How much is 1 kilogram?\n",
            "AI: 1 kilogram is equal to 1000 grams. It is a unit of mass in the metric system. Is there anything else you would like to know?\n",
            "Human: What is my name?\n",
            "AI: Your name is Alex.\n"
          ]
        }
      ],
      "source": [
        "conversation.predict(input=\"My name is Alex\")\n",
        "conversation.predict(input=\"How much is 1 kilogram?\")\n",
        "conversation.predict(input=\"What is my name?\")\n",
        "print(memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqcC8r5_vjul",
        "outputId": "3925092a-bb0f-44fb-fd5a-ed8ffcd51418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: I am Alex\n",
            "AI: Nice to meet you Alex\n"
          ]
        }
      ],
      "source": [
        "memory.load_memory_variables({})\n",
        "memory = ConversationBufferMemory()\n",
        "memory.save_context({\"input\": \"I am Alex\"},\n",
        "                    {\"output\": \"Nice to meet you Alex\"})\n",
        "print(memory.buffer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}